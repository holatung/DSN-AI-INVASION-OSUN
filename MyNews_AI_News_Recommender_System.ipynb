{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holatung/DSN-AI-INVASION-OSUN/blob/main/MyNews_AI_News_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code and algorithm are designed as part of the research on the call for papers on '**Recommender Systems in the Media, Creative, and Cultural Industries'**. A real-world production system would require much more sophisticated techniques, a larger dataset, and continuous monitoring for bias.\n",
        "\n",
        "With the growing dominance of online platforms in the media, creative, and cultural industries (MCCI), recommender systems have become omnipresent in MCCI, from production to distribution and consumption. These systems leverage training data, algorithms, and prediction models to deliver automated, flexible, and immediate responses tailored to the personal preferences of content consumers. By filtering, ranking, and eventually recommending content to users, recommender systems influence exposure in two ways: they can promote items that might otherwise go unnoticed, or they can hide, and thus virtually remove, other items. In both cases, algorithms are not neutral, raising important questions about how they are designed and implemented, who decides, and on what basis (Kunaver & Po≈ærl, 2017)\n",
        "\n",
        "**Algorithm: Content-Based Recommender System for News:**\n",
        "This algorithm recommends news articles by identifying articles with topics similar to those a user has shown interest in.\n",
        "\n",
        "* Data Preparation: The algorithm first requires a dataset of news articles. Each article needs to be associated with one or more of the specified categories: Politics, Entertainment, Lifestyle, Sports, Health, Business, Opinion, Tech, and Fashion.\n",
        "\n",
        "\n",
        "* User Profile Creation: For each user, a \"profile\" is created. This profile is a vector representing their interests. For example, if a user likes a \"Politics\" and a \"Tech\" article, their profile vector will have a positive value for those categories.\n",
        "\n",
        "* Content Vectorization: Each news article is also represented as a vector. For simplicity, we can use a one-hot encoding scheme where a '1' indicates the presence of a specific topic and a '0' indicates its absence.\n",
        "\n",
        "* Similarity Calculation: The core of the recommendation is calculating the similarity between the user's profile vector and the content vector of each unread news article. The algorithm uses Cosine Similarity, a common metric that measures the angle between two vectors. A smaller angle (closer to 1) means the vectors are more similar.\n",
        "\n",
        "* Recommendation Generation: The algorithm ranks the unread articles based on their similarity score. The top 'N' articles with the highest scores are then recommended to the user.\n",
        "\n",
        "This approach ensures that if a user reads and enjoys a \"Health\" article, they are more likely to see other \"Health\" or related articles, helping them discover relevant content within their interests.\n",
        "\n",
        "This Python code implements the algorithm described above. It uses a sample dataset and the *scikit-learn* library to perform the similarity calculations."
      ],
      "metadata": {
        "id": "GqioBwKcZgCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "def create_sample_dataset():\n",
        "    \"\"\"\n",
        "    Creates a sample dataset of news articles with their topics.\n",
        "    In a real application, this would be a large database or a DataFrame\n",
        "    loaded from a file.\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        'article_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
        "        'title': [\n",
        "            \"Presidential Race Heats Up\", \"New Movie Breaks Box Office Records\",\n",
        "            \"Simple Yoga Poses for Beginners\", \"Messi Scores Hat-Trick\",\n",
        "            \"New Study on Heart Disease\", \"Stock Market Sees Major Gains\",\n",
        "            \"Analyzing the Latest Policy Debate\", \"Fashion Week 2025 Highlights\",\n",
        "            \"Tech Giant Launches New Phone\", \"Debate on Climate Change Policy\",\n",
        "            \"Healthy Eating Tips\", \"New Fashion Trends for Fall\",\n",
        "            \"SpaceX Rocket Launch Successful\", \"Op-Ed: The Future of Democracy\",\n",
        "            \"Local Business Thrives\"\n",
        "        ],\n",
        "        'topics': [\n",
        "            'Politics', 'Entertainment', 'Health', 'Sports', 'Health',\n",
        "            'Business', 'Politics', 'Fashion', 'Tech', 'Politics',\n",
        "            'Health', 'Fashion', 'Tech', 'Opinion', 'Business'\n",
        "        ]\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def get_recommendations(user_id, num_recommendations=5):\n",
        "    \"\"\"\n",
        "    Generates news recommendations for a given user.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): The ID of the user.\n",
        "        num_recommendations (int): The number of articles to recommend.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of recommended article titles.\n",
        "    \"\"\"\n",
        "    # 1. Load data and simulate user interactions\n",
        "    articles_df = create_sample_dataset()\n",
        "    user_interactions = {\n",
        "        101: [1, 7, 10], # User 101 likes Politics articles\n",
        "        102: [2, 8, 11, 12], # User 102 likes Entertainment, Fashion, Health\n",
        "        103: [4, 6] # User 103 likes Sports and Business\n",
        "    }\n",
        "\n",
        "    if user_id not in user_interactions:\n",
        "        print(f\"User {user_id} not found. Providing random recommendations.\")\n",
        "        return random.sample(articles_df['title'].tolist(), num_recommendations)\n",
        "\n",
        "    liked_articles = articles_df[articles_df['article_id'].isin(user_interactions[user_id])]\n",
        "\n",
        "    # 2. Vectorize the topics\n",
        "    # We use a simple one-hot encoding for topics to create the feature matrix\n",
        "    all_topics = sorted(articles_df['topics'].unique().tolist())\n",
        "\n",
        "    def vectorize_topics(topics):\n",
        "        vector = [0] * len(all_topics)\n",
        "        for topic in topics.split(','):\n",
        "            if topic in all_topics:\n",
        "                vector[all_topics.index(topic)] = 1\n",
        "        return vector\n",
        "\n",
        "    articles_df['vector'] = articles_df['topics'].apply(vectorize_topics)\n",
        "\n",
        "    # 3. Create the user profile\n",
        "    user_profile_vector = [0] * len(all_topics)\n",
        "    for topic in liked_articles['topics']:\n",
        "        user_profile_vector[all_topics.index(topic)] = 1\n",
        "\n",
        "    # 4. Calculate similarity scores for unread articles\n",
        "    unread_articles = articles_df[~articles_df['article_id'].isin(user_interactions[user_id])]\n",
        "\n",
        "    # Calculate cosine similarity between the user profile and each unread article\n",
        "    similarity_scores = cosine_similarity([user_profile_vector], list(unread_articles['vector']))[0]\n",
        "\n",
        "    unread_articles['similarity_score'] = similarity_scores\n",
        "\n",
        "    # 5. Get top recommendations\n",
        "    recommended_articles = unread_articles.sort_values(\n",
        "        by='similarity_score', ascending=False\n",
        "    ).head(num_recommendations)\n",
        "\n",
        "    return recommended_articles['title'].tolist()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage for different users\n",
        "    user_101_recs = get_recommendations(user_id=101)\n",
        "    print(\"Recommendations for User 101 (likes Politics):\")\n",
        "    for rec in user_101_recs:\n",
        "        print(f\"- {rec}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    user_102_recs = get_recommendations(user_id=102)\n",
        "    print(\"Recommendations for User 102 (likes Entertainment, Fashion, Health):\")\n",
        "    for rec in user_102_recs:\n",
        "        print(f\"- {rec}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    user_103_recs = get_recommendations(user_id=103)\n",
        "    print(\"Recommendations for User 103 (likes Sports and Business):\")\n",
        "    for rec in user_103_recs:\n",
        "        print(f\"- {rec}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for User 101 (likes Politics):\n",
            "- New Movie Breaks Box Office Records\n",
            "- Simple Yoga Poses for Beginners\n",
            "- Messi Scores Hat-Trick\n",
            "- New Study on Heart Disease\n",
            "- Stock Market Sees Major Gains\n",
            "\n",
            "==================================================\n",
            "\n",
            "Recommendations for User 102 (likes Entertainment, Fashion, Health):\n",
            "- Simple Yoga Poses for Beginners\n",
            "- New Study on Heart Disease\n",
            "- Presidential Race Heats Up\n",
            "- Messi Scores Hat-Trick\n",
            "- Stock Market Sees Major Gains\n",
            "\n",
            "==================================================\n",
            "\n",
            "Recommendations for User 103 (likes Sports and Business):\n",
            "- Local Business Thrives\n",
            "- New Movie Breaks Box Office Records\n",
            "- Simple Yoga Poses for Beginners\n",
            "- New Study on Heart Disease\n",
            "- Presidential Race Heats Up\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1265647260.py:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  unread_articles['similarity_score'] = similarity_scores\n",
            "/tmp/ipython-input-1265647260.py:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  unread_articles['similarity_score'] = similarity_scores\n",
            "/tmp/ipython-input-1265647260.py:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  unread_articles['similarity_score'] = similarity_scores\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTLRrmrKWZQs",
        "outputId": "b12971ad-f92a-4158-e76e-5de72bd7657f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "This Python code implements the algorithm described above. It uses a sample dataset and the scikit-learn library to perform the similarity calculations."
      ],
      "metadata": {
        "id": "eDVMKmdYalHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}